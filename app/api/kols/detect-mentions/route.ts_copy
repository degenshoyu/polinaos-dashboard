// app/api/kols/detect-mentions/route.ts
import { NextResponse } from "next/server";
import { z } from "zod";
import { getServerSession } from "next-auth";
import { authOptions } from "@/lib/auth";
import { db } from "@/lib/db/client";
import { kolTweets, tweetTokenMentions, mentionSource } from "@/lib/db/schema";
import { eq, and, gte, lt, sql, inArray, desc } from "drizzle-orm";
import { extractMentions, type Mention } from "@/lib/tokens/extract";
import { buildTriggerKeyWithText } from "@/lib/tokens/triggerKey";
import {
  resolveTickersToContracts,
  resolveContractsToMeta,
  resolveNamesToContracts,
} from "@/lib/markets/geckoterminal";
import { canonAddr } from "@/lib/chains/address";

export const runtime = "nodejs";
export const dynamic = "force-dynamic";

/* ========================= Auth helpers ========================= */
function allowByCronSecret(req: Request) {
  const expected = (process.env.CRON_SECRET || "").trim();
  if (!expected) return false;
  const url = new URL(req.url);
  const q = url.searchParams.get("secret")?.trim() || "";
  const h =
    req.headers.get("x-cron-secret")?.trim() ||
    req.headers.get("x-api-key")?.trim() ||
    "";
  return q === expected || h === expected;
}

/* ========================= Body schema ========================= */
const Body = z.object({
  screen_name: z.string().min(1),
  days: z.number().int().min(1).max(30).optional().default(7),
  missingOnly: z.boolean().optional().default(true),
});

/* ========================= Trigger helpers ========================= */
// Prefer readable input for trigger text
function triggerInputFor(m: Mention) {
  if (m.source === "phrase") return m.tokenDisplay || m.tokenKey || "";
  if (m.source === "ca") return m.tokenKey || "";
  if (m.tokenDisplay?.startsWith("$")) return m.tokenDisplay;
  return `$${String(m.tokenKey || "").toUpperCase()}`;
}

// Deterministic fallback trigger key that does not depend on in-text offsets
function makeDeterministicTriggerKey(m: Mention): string {
  if (m.source === "ca") {
    const addr = canonAddr(String(m.tokenKey || ""));
    return addr ? `ca:${addr}` : "ca:unknown";
  }
  if (m.source === "ticker") {
    return `tk:${String(m.tokenKey || "").toLowerCase()}`;
  }
  if (m.source === "phrase") {
    return `ph:${String(m.tokenKey || "").toLowerCase()}`;
  }
  return `uk:${String(m.tokenKey || "").toLowerCase()}`;
}

/* ========================= CA reconstruction (conservative) ========================= */
/** Base58 (32–44) for plain scan */
const SOL_CA_RE = /\b[1-9A-HJ-NP-Za-km-z]{32,44}\b/g;

/**
 * Extract CA from pump.fun URLs even if broken after "/coin/".
 * We DO NOT remove normal whitespaces globally — only glue base58 fragments around the URL tail.
 */
function collectFromPumpFun(text: string): string[] {
  const out: string[] = [];
  const RE = /pump\.fun\/coin\/([^\s]{1,90})/gi;
  let m: RegExpExecArray | null;
  while ((m = RE.exec(text)) !== null) {
    const tail = m[1] || "";
    // Look ahead a bit and glue base58-looking fragments (no whitespace removal elsewhere)
    const rest = text.slice(RE.lastIndex, RE.lastIndex + 160);
    const more = (rest.match(/[1-9A-HJ-NP-Za-km-z]{2,}/g) || []).join("");
    const candidate = (tail + more).replace(/[^1-9A-HJ-NP-Za-km-z]+/g, "");
    const clipped = candidate.slice(0, 64);
    for (let L = Math.min(44, clipped.length); L >= 32; L--) {
      const head = clipped.slice(0, L);
      if (/^[1-9A-HJ-NP-Za-km-z]{32,44}$/.test(head)) {
        out.push(head);
        break;
      }
    }
  }
  return out;
}

/**
 * Join TWO base58 chunks split by whitespace/newline:
 *   "8mznFjdcG\nHhfvxkP1JVC7T...cipump" → "8mznFjdcGHhfvxkP1JVC7T...cipump"
 * We do NOT touch any other whitespaces in normal sentences.
 */
function collectJoinedPairs(text: string): string[] {
  const out: string[] = [];
  // left chunk 8–20, right chunk 16–44 → joined candidate 32–64, then validate 32–44
  const SPLIT2 =
    /\b([1-9A-HJ-NP-Za-km-z]{8,20})\s+([1-9A-HJ-NP-Za-km-z]{16,44})\b/g;
  let m: RegExpExecArray | null;
  while ((m = SPLIT2.exec(text)) !== null) {
    const a = m[1];
    const b = m[2];
    const joined = (a + b).trim();
    if (/^[1-9A-HJ-NP-Za-km-z]{32,44}$/.test(joined)) out.push(joined);
  }
  return out;
}

/** Keep only maximal/longest CAs: drop any CA that is a strict substring of another CA. */
function filterCAKeepMaximal(cas: string[]): Set<string> {
  const uniq = Array.from(new Set(cas));
  const keep = new Set<string>();
  for (const a of uniq) {
    let isSub = false;
    for (const b of uniq) {
      if (a === b) continue;
      if (b.includes(a)) {
        isSub = true;
        break;
      }
    }
    if (!isSub) keep.add(a);
  }
  return keep;
}

/** Plain scan (no global whitespace change) + pump.fun fix + two-chunk join → keep longest */
function reconstructCAsFromTweet(text: string): Set<string> {
  const plain = (text || "").match(SOL_CA_RE) ?? [];
  const fromPump = collectFromPumpFun(text || "");
  const joined = collectJoinedPairs(text || "");
  return filterCAKeepMaximal([...plain, ...fromPump, ...joined]);
}

/* ========================= Route ========================= */
export async function POST(req: Request) {
  // Admin or CRON auth
  const session = await getServerSession(authOptions);
  const isAdmin = Boolean((session?.user as any)?.isAdmin);
  const bySecret = allowByCronSecret(req);
  if (!isAdmin && !bySecret) {
    return NextResponse.json(
      { ok: false, error: "forbidden" },
      { status: 403 },
    );
  }

  const { screen_name, days, missingOnly } = Body.parse(await req.json());
  const handle = screen_name.trim().replace(/^@+/, "").toLowerCase();
  const isAll = handle === "*" || handle === "all";

  // Time window [since, until)
  const now = new Date();
  const since = new Date(now);
  since.setDate(now.getDate() - (days - 1));
  const until = new Date(now);
  until.setDate(now.getDate() + 1);

  // Load tweets
  const tweets = await db
    .select({
      tweetId: kolTweets.tweetId,
      textContent: kolTweets.textContent,
      published: kolTweets.publishDate,
    })
    .from(kolTweets)
    .where(
      isAll
        ? and(
            gte(kolTweets.publishDate, since),
            lt(kolTweets.publishDate, until),
          )
        : and(
            eq(kolTweets.twitterUsername, handle),
            gte(kolTweets.publishDate, since),
            lt(kolTweets.publishDate, until),
          ),
    )
    .orderBy(desc(kolTweets.publishDate));

  if (!tweets.length) {
    return NextResponse.json({
      ok: true,
      handle: isAll ? "*" : handle,
      days,
      scannedTweets: 0,
      mentionsDetected: 0,
      inserted: 0,
      updated: 0,
    });
  }

  // When missingOnly=true, skip tweets that already have ANY mentions
  let candidates = tweets;
  if (missingOnly) {
    const existing = await db
      .select({ tweetId: tweetTokenMentions.tweetId })
      .from(tweetTokenMentions)
      .where(
        inArray(
          tweetTokenMentions.tweetId,
          tweets.map((t) => t.tweetId),
        ),
      );
    const has = new Set(existing.map((e) => e.tweetId));
    candidates = tweets.filter((t) => !has.has(t.tweetId));
  }

  // Extract mentions; aggregate tickers/names/CAs, build trigger tuples
  const all: {
    tweetId: string;
    m: Mention;
    triggerKey: string;
    triggerText: string;
  }[] = [];
  const uniqueTickers = new Set<string>(); // "$TICKER"
  const phraseNames = new Set<string>(); // "<name> coin"
  const caSet = new Set<string>(); // canonical contract addresses

  for (const t of candidates) {
    // 1) Reconstruct CAs conservatively (NO global whitespace removal)
    const rebuiltCAs = reconstructCAsFromTweet(t.textContent ?? "");

    // 2) Run normal extraction for ticker/phrase (and CA fallback)
    let ext = extractMentions(t.textContent ?? "");

    // 3) Replace CA mentions with reconstructed/longest CAs to avoid half pieces
    if (rebuiltCAs.size) {
      ext = ext.filter((x) => x.source !== "ca");
      for (const addr of rebuiltCAs) {
        ext.push({
          tokenKey: addr,
          tokenDisplay: addr,
          source: "ca",
          confidence: 100,
        } as Mention);
      }
    }

    // 4) Build trigger tuples
    for (const m of ext) {
      const input = triggerInputFor(m);

      let trigKey = "";
      let trigText = "";

      if (m.source === "ca") {
        // Always use deterministic trigger key for CA
        const addr = String(m.tokenKey || "");
        trigKey = makeDeterministicTriggerKey(m); // "ca:<base58>"
        trigText = addr || input; // show reconstructed full CA
      } else {
        const built = buildTriggerKeyWithText({
          source: m.source as any,
          value: input,
        });
        trigKey = (built as any)?.key || "";
        trigText = (built as any)?.text || input;
        if (!trigKey) {
          // ultimate fallback
          trigKey = makeDeterministicTriggerKey(m);
        }
      }

      all.push({
        tweetId: t.tweetId,
        m,
        triggerKey: trigKey,
        triggerText: trigText,
      });

      // Aggregate for later resolution
      if (m.source === "ca") {
        const addr = canonAddr(String(m.tokenKey || ""));
        if (addr) caSet.add(addr);
      } else if (m.source === "ticker") {
        const tk = m.tokenDisplay?.startsWith("$")
          ? m.tokenDisplay
          : `$${String(m.tokenKey || "").toUpperCase()}`;
        uniqueTickers.add(tk);
      } else if (m.source === "phrase") {
        const name = (m.tokenDisplay || m.tokenKey || "").trim();
        if (name) phraseNames.add(name);
      }
    }
  }

  // Resolve to contracts (Solana-only): tickers + phrase names
  let resolved = new Map<
    string,
    { tokenKey: string; tokenDisplay: string; boostedConf: number }
  >();
  let resolvedNames = new Map<
    string,
    { tokenKey: string; tokenDisplay: string; boostedConf: number }
  >();
  try {
    resolved = await resolveTickersToContracts([...uniqueTickers]);
  } catch (e) {
    console.warn("[detect-mentions] resolveTickersToContracts failed", e);
  }
  try {
    resolvedNames = await resolveNamesToContracts([...phraseNames]);
  } catch (e) {
    console.warn("[detect-mentions] resolveNamesToContracts failed", e);
  }

  // Reverse map: contract -> { tokenDisplay, boostedConf }
  const byContract = new Map<
    string,
    { tokenDisplay: string; boostedConf: number }
  >();
  for (const [, r] of resolved.entries()) {
    const addr = canonAddr(String(r.tokenKey || ""));
    if (addr)
      byContract.set(addr, {
        tokenDisplay: r.tokenDisplay,
        boostedConf: r.boostedConf,
      });
  }

  // CA-only resolution: resolve contracts that have no meta yet
  const missingCA = Array.from(caSet).filter((a) => !byContract.has(a));
  if (missingCA.length) {
    let caMeta = new Map<
      string,
      { tokenKey: string; tokenDisplay: string; boostedConf: number }
    >();
    try {
      caMeta = await resolveContractsToMeta(missingCA);
    } catch (e) {
      console.warn("[detect-mentions] resolveContractsToMeta failed", e);
    }
    for (const [addr, meta] of caMeta.entries()) {
      byContract.set(addr, {
        tokenDisplay: meta.tokenDisplay,
        boostedConf: meta.boostedConf,
      });
    }
    console.debug("[detect-mentions] CA resolved via GT", {
      total: missingCA.length,
      hit: Array.from(caMeta.keys()).length,
    });
  }

  // Build DB rows; de-duplicate by (tweetId, triggerKey)
  type Row = {
    tweetId: string;
    tokenKey: string;
    tokenDisplay: string | null;
    confidence: number;
    source: (typeof mentionSource.enumValues)[number];
    triggerKey: string;
    triggerText: string | null;
  };
  const rows: Row[] = [];
  const seenPair = new Set<string>();

  for (const { tweetId, m, triggerKey, triggerText } of all) {
    let tokenKey = m.tokenKey;
    let tokenDisplay = m.tokenDisplay;
    let confidence = m.confidence;

    if (m.source === "ca") {
      // CA: map to a friendly $SYMBOL when possible
      const addr = canonAddr(String(m.tokenKey || ""));
      tokenKey = addr;
      const meta = addr ? byContract.get(addr) : undefined;
      if (meta?.tokenDisplay) {
        tokenDisplay = meta.tokenDisplay;
        confidence = Math.max(confidence, meta.boostedConf ?? 0);
      } else {
        // Last resort: synthesize a short tag for visibility
        const short = addr ? `${addr.slice(0, 4)}…${addr.slice(-4)}` : "????";
        tokenDisplay = `$${short}`;
        // keep confidence 100 for direct CA mentions
      }
    } else if (m.source === "ticker") {
      const disp = m.tokenDisplay?.startsWith("$")
        ? m.tokenDisplay
        : `$${String(m.tokenKey || "").toUpperCase()}`;
      const r = resolved.get(disp.replace(/^\$+/, "").toLowerCase());
      if (r) {
        tokenKey = r.tokenKey;
        tokenDisplay = r.tokenDisplay;
        confidence = Math.max(confidence, r.boostedConf);
      }
    } else if (m.source === "phrase") {
      const q = (m.tokenDisplay || m.tokenKey || "").trim().toLowerCase();
      const r = resolvedNames.get(q);
      if (!r) {
        // skip unresolved phrase to keep table clean
        continue;
      }
      tokenKey = r.tokenKey;
      tokenDisplay = r.tokenDisplay;
      confidence = Math.max(confidence, r.boostedConf);
    }

    const pair = `${tweetId}___${triggerKey}`;
    if (seenPair.has(pair)) continue;
    seenPair.add(pair);

    rows.push({
      tweetId,
      tokenKey: canonAddr(String(tokenKey || "")),
      tokenDisplay: tokenDisplay ?? (m.tokenDisplay || m.tokenKey),
      confidence: Math.min(100, Math.max(0, Math.round(confidence))),
      source: m.source as any as Row["source"],
      triggerKey,
      triggerText,
    });
  }

  if (!rows.length) {
    return NextResponse.json({
      ok: true,
      handle,
      days,
      scannedTweets: candidates.length,
      mentionsDetected: 0,
      inserted: 0,
      updated: 0,
    });
  }

  // Accurate counts via pre-check (existing pairs)
  const tweetIds = Array.from(new Set(rows.map((r) => r.tweetId)));
  const triggers = Array.from(new Set(rows.map((r) => r.triggerKey)));
  const existingPairs = await db
    .select({
      tweetId: tweetTokenMentions.tweetId,
      triggerKey: tweetTokenMentions.triggerKey,
      tokenKey: tweetTokenMentions.tokenKey,
    })
    .from(tweetTokenMentions)
    .where(
      and(
        inArray(tweetTokenMentions.tweetId, tweetIds),
        inArray(tweetTokenMentions.triggerKey, triggers),
      ),
    );

  const existsMap = new Map(
    existingPairs.map((e) => [`${e.tweetId}___${e.triggerKey}`, e.tokenKey]),
  );
  const willInsert = rows.filter(
    (r) => !existsMap.has(`${r.tweetId}___${r.triggerKey}`),
  ).length;
  const willUpdate = rows.filter((r) => {
    const prev = existsMap.get(`${r.tweetId}___${r.triggerKey}`);
    return prev && prev !== r.tokenKey;
  }).length;

  // Upsert by (tweet_id, trigger_key), chunked
  const CHUNK = 200;
  for (let i = 0; i < rows.length; i += CHUNK) {
    const chunk = rows.slice(i, i + CHUNK);
    await db
      .insert(tweetTokenMentions)
      .values(chunk)
      .onConflictDoUpdate({
        target: [tweetTokenMentions.tweetId, tweetTokenMentions.triggerKey],
        set: {
          tokenKey: sql`excluded.token_key`,
          tokenDisplay: sql`excluded.token_display`,
          confidence: sql`excluded.confidence`,
          source: sql`excluded.source`,
          triggerText: sql`excluded.trigger_text`,
          updatedAt: sql`now()`,
        },
      });
  }

  return NextResponse.json({
    ok: true,
    handle,
    days,
    scannedTweets: candidates.length,
    mentionsDetected: rows.length,
    inserted: willInsert,
    updated: willUpdate,
  });
}
